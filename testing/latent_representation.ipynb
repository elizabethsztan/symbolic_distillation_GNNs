{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the latent representations: activations of the message functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from model import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "data = load_data('../simulations/datasets/r1_n=3_dim=2_nt=1000_dt=0.005')\n",
    "X, y = data\n",
    "\n",
    "#make train, test, val sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25: 100%|██████████| 313/313 [00:02<00:00, 156.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.9727, val loss: 1.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/25: 100%|██████████| 313/313 [00:01<00:00, 202.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.7122, val loss: 1.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/25: 100%|██████████| 313/313 [00:01<00:00, 186.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.5743, val loss: 1.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/25: 100%|██████████| 313/313 [00:01<00:00, 203.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.4792, val loss: 1.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/25: 100%|██████████| 313/313 [00:01<00:00, 205.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3847, val loss: 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6/25: 100%|██████████| 313/313 [00:01<00:00, 191.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3622, val loss: 0.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7/25: 100%|██████████| 313/313 [00:01<00:00, 178.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3206, val loss: 0.7420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8/25: 100%|██████████| 313/313 [00:01<00:00, 196.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3023, val loss: 0.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9/25: 100%|██████████| 313/313 [00:01<00:00, 178.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3029, val loss: 0.7552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10/25: 100%|██████████| 313/313 [00:01<00:00, 187.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2748, val loss: 0.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11/25: 100%|██████████| 313/313 [00:02<00:00, 126.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2460, val loss: 0.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12/25: 100%|██████████| 313/313 [00:01<00:00, 163.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2496, val loss: 0.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13/25: 100%|██████████| 313/313 [00:01<00:00, 169.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2339, val loss: 0.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14/25: 100%|██████████| 313/313 [00:01<00:00, 161.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2524, val loss: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15/25: 100%|██████████| 313/313 [00:02<00:00, 154.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2134, val loss: 0.5945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16/25: 100%|██████████| 313/313 [00:01<00:00, 157.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2077, val loss: 0.6185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17/25: 100%|██████████| 313/313 [00:01<00:00, 163.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2447, val loss: 0.6241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18/25: 100%|██████████| 313/313 [00:01<00:00, 157.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2056, val loss: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19/25: 100%|██████████| 313/313 [00:01<00:00, 161.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2052, val loss: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20/25: 100%|██████████| 313/313 [00:01<00:00, 158.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2325, val loss: 0.6317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21/25: 100%|██████████| 313/313 [00:02<00:00, 149.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.1841, val loss: 0.6637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22/25: 100%|██████████| 313/313 [00:02<00:00, 134.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.1972, val loss: 0.6327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 23/25: 100%|██████████| 313/313 [00:01<00:00, 163.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.1802, val loss: 0.5610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24/25: 100%|██████████| 313/313 [00:01<00:00, 168.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.1983, val loss: 0.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 25/25: 100%|██████████| 313/313 [00:01<00:00, 167.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.1872, val loss: 0.5762\n"
     ]
    }
   ],
   "source": [
    "cutoff = 10000\n",
    "val_cutoff = 2500\n",
    "\n",
    "#train the model on a small amount of data\n",
    "model = train((X_train[:cutoff], y_train[:cutoff]), (X_val[:cutoff], y_val[:cutoff]), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_features(test_data, model):\n",
    "    with torch.no_grad():\n",
    "        batches, nodes, _ = test_data.size()\n",
    "        message_dim = 100 #standard message size \n",
    "        messages = torch.zeros(batches, nodes, nodes, message_dim)\n",
    "        for batch in range(batches):\n",
    "            for i in range(nodes):\n",
    "                for j in range(nodes):\n",
    "                    if i != j:\n",
    "                        x_i = test_data[batch, i].unsqueeze(0)\n",
    "                        x_j = test_data[batch, j].unsqueeze(0)\n",
    "                        msg = model.message(x_i, x_j)\n",
    "\n",
    "                        messages[batch, i, j] = msg\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wee = message_features(X_test[:500], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wee[:,0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_info(model, input_data, batch_size=32):\n",
    "    \"\"\"\n",
    "    Analyzes the messages passed between nodes in the NBodyGNN model.\n",
    "    \n",
    "    Args:\n",
    "        model (NBodyGNN): Trained model instance\n",
    "        input_data (torch.Tensor): Input data with shape [no_timesteps, no_nodes, node_features]\n",
    "        batch_size (int): Size of batches to process\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing node features and message information\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    edge_index = get_edge_index(input_data.shape[1])\n",
    "    \n",
    "    # Create dataloader for batch processing\n",
    "    dataset = TensorDataset(input_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_messages = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (nodes,) in dataloader:\n",
    "            # Get source and target node features for each edge\n",
    "            s1 = nodes[:, edge_index[0]]  # Source nodes\n",
    "            s2 = nodes[:, edge_index[1]]  # Target nodes\n",
    "            \n",
    "            # Concatenate features and pass through edge model\n",
    "            edge_features = torch.cat((s1, s2), dim=-1)\n",
    "            messages = model.edge_model(edge_features)\n",
    "            \n",
    "            # Combine node features with messages\n",
    "            batch_messages = torch.cat((s1, s2, messages), dim=-1)\n",
    "            \n",
    "            # Reshape batch_messages to be 2D: [batch_size * num_edges, features]\n",
    "            batch_messages = batch_messages.reshape(-1, batch_messages.shape[-1])\n",
    "            all_messages.append(batch_messages)\n",
    "    \n",
    "    # Combine all batches\n",
    "    all_messages = torch.cat(all_messages, dim=0)\n",
    "    \n",
    "    # Convert to numpy for DataFrame creation\n",
    "    all_messages = all_messages.numpy()\n",
    "    \n",
    "    # Create column names\n",
    "    node_features = ['x', 'y', 'vx', 'vy', 'q', 'm']  # Based on your 2D implementation\n",
    "    source_cols = [f'{f}1' for f in node_features]\n",
    "    target_cols = [f'{f}2' for f in node_features]\n",
    "    message_cols = [f'e{i}' for i in range(messages.shape[-1])]\n",
    "    columns = source_cols + target_cols + message_cols\n",
    "    \n",
    "    # Create DataFrame\n",
    "    msg_info = pd.DataFrame(all_messages, columns=columns)\n",
    "    \n",
    "    # Calculate physical quantities\n",
    "    msg_info['dx'] = msg_info.x1 - msg_info.x2\n",
    "    msg_info['dy'] = msg_info.y1 - msg_info.y2\n",
    "    msg_info['r'] = np.sqrt(msg_info.dx**2 + msg_info.dy**2)\n",
    "    \n",
    "    # Calculate relative velocities\n",
    "    msg_info['dvx'] = msg_info.vx1 - msg_info.vx2\n",
    "    msg_info['dvy'] = msg_info.vy1 - msg_info.vy2\n",
    "    msg_info['v_rel'] = np.sqrt(msg_info.dvx**2 + msg_info.dvy**2)\n",
    "    \n",
    "    return msg_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>vx1</th>\n",
       "      <th>vy1</th>\n",
       "      <th>q1</th>\n",
       "      <th>m1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>vx2</th>\n",
       "      <th>vy2</th>\n",
       "      <th>...</th>\n",
       "      <th>e96</th>\n",
       "      <th>e97</th>\n",
       "      <th>e98</th>\n",
       "      <th>e99</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>r</th>\n",
       "      <th>dvx</th>\n",
       "      <th>dvy</th>\n",
       "      <th>v_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.108470</td>\n",
       "      <td>-3.027177</td>\n",
       "      <td>-0.107625</td>\n",
       "      <td>-0.693829</td>\n",
       "      <td>-0.871233</td>\n",
       "      <td>1.801894</td>\n",
       "      <td>1.019855</td>\n",
       "      <td>-3.755330</td>\n",
       "      <td>0.474216</td>\n",
       "      <td>-1.642119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032894</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.066830</td>\n",
       "      <td>0.357321</td>\n",
       "      <td>0.088615</td>\n",
       "      <td>0.728153</td>\n",
       "      <td>0.733526</td>\n",
       "      <td>-0.581841</td>\n",
       "      <td>0.948290</td>\n",
       "      <td>1.112561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.108470</td>\n",
       "      <td>-3.027177</td>\n",
       "      <td>-0.107625</td>\n",
       "      <td>-0.693829</td>\n",
       "      <td>-0.871233</td>\n",
       "      <td>1.801894</td>\n",
       "      <td>2.941403</td>\n",
       "      <td>-0.552212</td>\n",
       "      <td>2.070446</td>\n",
       "      <td>-1.332116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015355</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>-0.071077</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>-1.832933</td>\n",
       "      <td>-2.474966</td>\n",
       "      <td>3.079789</td>\n",
       "      <td>-2.178071</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>2.269670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019855</td>\n",
       "      <td>-3.755330</td>\n",
       "      <td>0.474216</td>\n",
       "      <td>-1.642119</td>\n",
       "      <td>-1.288934</td>\n",
       "      <td>1.142944</td>\n",
       "      <td>1.108470</td>\n",
       "      <td>-3.027177</td>\n",
       "      <td>-0.107625</td>\n",
       "      <td>-0.693829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131412</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>-0.475665</td>\n",
       "      <td>0.393173</td>\n",
       "      <td>-0.088615</td>\n",
       "      <td>-0.728153</td>\n",
       "      <td>0.733526</td>\n",
       "      <td>0.581841</td>\n",
       "      <td>-0.948290</td>\n",
       "      <td>1.112561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.019855</td>\n",
       "      <td>-3.755330</td>\n",
       "      <td>0.474216</td>\n",
       "      <td>-1.642119</td>\n",
       "      <td>-1.288934</td>\n",
       "      <td>1.142944</td>\n",
       "      <td>2.941403</td>\n",
       "      <td>-0.552212</td>\n",
       "      <td>2.070446</td>\n",
       "      <td>-1.332116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018540</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>-0.075058</td>\n",
       "      <td>0.150679</td>\n",
       "      <td>-1.921548</td>\n",
       "      <td>-3.203119</td>\n",
       "      <td>3.735280</td>\n",
       "      <td>-1.596229</td>\n",
       "      <td>-0.310002</td>\n",
       "      <td>1.626053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.941403</td>\n",
       "      <td>-0.552212</td>\n",
       "      <td>2.070446</td>\n",
       "      <td>-1.332116</td>\n",
       "      <td>0.595053</td>\n",
       "      <td>0.623231</td>\n",
       "      <td>1.108470</td>\n",
       "      <td>-3.027177</td>\n",
       "      <td>-0.107625</td>\n",
       "      <td>-0.693829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015953</td>\n",
       "      <td>0.131964</td>\n",
       "      <td>-0.052329</td>\n",
       "      <td>0.305343</td>\n",
       "      <td>1.832933</td>\n",
       "      <td>2.474966</td>\n",
       "      <td>3.079789</td>\n",
       "      <td>2.178071</td>\n",
       "      <td>-0.638288</td>\n",
       "      <td>2.269670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1.490004</td>\n",
       "      <td>0.604459</td>\n",
       "      <td>0.959115</td>\n",
       "      <td>1.252741</td>\n",
       "      <td>0.495583</td>\n",
       "      <td>1.296262</td>\n",
       "      <td>0.835605</td>\n",
       "      <td>0.783813</td>\n",
       "      <td>-0.987951</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146489</td>\n",
       "      <td>-0.021632</td>\n",
       "      <td>-0.271225</td>\n",
       "      <td>0.310987</td>\n",
       "      <td>0.654399</td>\n",
       "      <td>-0.179354</td>\n",
       "      <td>0.678532</td>\n",
       "      <td>1.947065</td>\n",
       "      <td>1.261998</td>\n",
       "      <td>2.320281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-1.636888</td>\n",
       "      <td>1.912824</td>\n",
       "      <td>-0.466934</td>\n",
       "      <td>0.984240</td>\n",
       "      <td>1.361227</td>\n",
       "      <td>0.673946</td>\n",
       "      <td>1.490004</td>\n",
       "      <td>0.604459</td>\n",
       "      <td>0.959115</td>\n",
       "      <td>1.252741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052281</td>\n",
       "      <td>0.022073</td>\n",
       "      <td>-0.054082</td>\n",
       "      <td>0.103952</td>\n",
       "      <td>-3.126891</td>\n",
       "      <td>1.308365</td>\n",
       "      <td>3.389582</td>\n",
       "      <td>-1.426049</td>\n",
       "      <td>-0.268502</td>\n",
       "      <td>1.451106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-1.636888</td>\n",
       "      <td>1.912824</td>\n",
       "      <td>-0.466934</td>\n",
       "      <td>0.984240</td>\n",
       "      <td>1.361227</td>\n",
       "      <td>0.673946</td>\n",
       "      <td>0.835605</td>\n",
       "      <td>0.783813</td>\n",
       "      <td>-0.987951</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056636</td>\n",
       "      <td>0.032347</td>\n",
       "      <td>-0.050118</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-2.472492</td>\n",
       "      <td>1.129011</td>\n",
       "      <td>2.718066</td>\n",
       "      <td>0.521016</td>\n",
       "      <td>0.993497</td>\n",
       "      <td>1.121826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.835605</td>\n",
       "      <td>0.783813</td>\n",
       "      <td>-0.987951</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-1.039976</td>\n",
       "      <td>1.101690</td>\n",
       "      <td>1.490004</td>\n",
       "      <td>0.604459</td>\n",
       "      <td>0.959115</td>\n",
       "      <td>1.252741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114410</td>\n",
       "      <td>0.193582</td>\n",
       "      <td>0.061398</td>\n",
       "      <td>0.211932</td>\n",
       "      <td>-0.654399</td>\n",
       "      <td>0.179354</td>\n",
       "      <td>0.678532</td>\n",
       "      <td>-1.947065</td>\n",
       "      <td>-1.261998</td>\n",
       "      <td>2.320281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.835605</td>\n",
       "      <td>0.783813</td>\n",
       "      <td>-0.987951</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-1.039976</td>\n",
       "      <td>1.101690</td>\n",
       "      <td>-1.636888</td>\n",
       "      <td>1.912824</td>\n",
       "      <td>-0.466934</td>\n",
       "      <td>0.984240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>-0.087123</td>\n",
       "      <td>0.172144</td>\n",
       "      <td>2.472492</td>\n",
       "      <td>-1.129011</td>\n",
       "      <td>2.718066</td>\n",
       "      <td>-0.521016</td>\n",
       "      <td>-0.993497</td>\n",
       "      <td>1.121826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        y1       vx1       vy1        q1        m1        x2  \\\n",
       "0     1.108470 -3.027177 -0.107625 -0.693829 -0.871233  1.801894  1.019855   \n",
       "1     1.108470 -3.027177 -0.107625 -0.693829 -0.871233  1.801894  2.941403   \n",
       "2     1.019855 -3.755330  0.474216 -1.642119 -1.288934  1.142944  1.108470   \n",
       "3     1.019855 -3.755330  0.474216 -1.642119 -1.288934  1.142944  2.941403   \n",
       "4     2.941403 -0.552212  2.070446 -1.332116  0.595053  0.623231  1.108470   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2995  1.490004  0.604459  0.959115  1.252741  0.495583  1.296262  0.835605   \n",
       "2996 -1.636888  1.912824 -0.466934  0.984240  1.361227  0.673946  1.490004   \n",
       "2997 -1.636888  1.912824 -0.466934  0.984240  1.361227  0.673946  0.835605   \n",
       "2998  0.835605  0.783813 -0.987951 -0.009257 -1.039976  1.101690  1.490004   \n",
       "2999  0.835605  0.783813 -0.987951 -0.009257 -1.039976  1.101690 -1.636888   \n",
       "\n",
       "            y2       vx2       vy2  ...       e96       e97       e98  \\\n",
       "0    -3.755330  0.474216 -1.642119  ...  0.032894  0.065366  0.066830   \n",
       "1    -0.552212  2.070446 -1.332116  ... -0.015355  0.007645 -0.071077   \n",
       "2    -3.027177 -0.107625 -0.693829  ...  0.131412  0.010498 -0.475665   \n",
       "3    -0.552212  2.070446 -1.332116  ... -0.018540  0.012951 -0.075058   \n",
       "4    -3.027177 -0.107625 -0.693829  ...  0.015953  0.131964 -0.052329   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2995  0.783813 -0.987951 -0.009257  ...  0.146489 -0.021632 -0.271225   \n",
       "2996  0.604459  0.959115  1.252741  ... -0.052281  0.022073 -0.054082   \n",
       "2997  0.783813 -0.987951 -0.009257  ... -0.056636  0.032347 -0.050118   \n",
       "2998  0.604459  0.959115  1.252741  ... -0.114410  0.193582  0.061398   \n",
       "2999  1.912824 -0.466934  0.984240  ...  0.005822  0.007030 -0.087123   \n",
       "\n",
       "           e99        dx        dy         r       dvx       dvy     v_rel  \n",
       "0     0.357321  0.088615  0.728153  0.733526 -0.581841  0.948290  1.112561  \n",
       "1     0.153527 -1.832933 -2.474966  3.079789 -2.178071  0.638288  2.269670  \n",
       "2     0.393173 -0.088615 -0.728153  0.733526  0.581841 -0.948290  1.112561  \n",
       "3     0.150679 -1.921548 -3.203119  3.735280 -1.596229 -0.310002  1.626053  \n",
       "4     0.305343  1.832933  2.474966  3.079789  2.178071 -0.638288  2.269670  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2995  0.310987  0.654399 -0.179354  0.678532  1.947065  1.261998  2.320281  \n",
       "2996  0.103952 -3.126891  1.308365  3.389582 -1.426049 -0.268502  1.451106  \n",
       "2997  0.102044 -2.472492  1.129011  2.718066  0.521016  0.993497  1.121826  \n",
       "2998  0.211932 -0.654399  0.179354  0.678532 -1.947065 -1.261998  2.320281  \n",
       "2999  0.172144  2.472492 -1.129011  2.718066 -0.521016 -0.993497  1.121826  \n",
       "\n",
       "[3000 rows x 118 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_info(model, X_test[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
